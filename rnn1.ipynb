{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOl98O4a8cxCh2yriXhYGXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi9rocks/DeepStuff/blob/master/rnn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_suAdxeweWC",
        "outputId": "4cbb0b5a-bdd7-4e8b-a7c0-53f1da224853"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJTHoQnWwpfV",
        "outputId": "3b2c3e59-ae95-45e2-da08-3feea6aef0cc"
      },
      "source": [
        "%cd '/content/gdrive/My Drive/RNN/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWcY120TxBVz",
        "outputId": "783b3a2f-96c5-415f-a2da-3258b7c528a4"
      },
      "source": [
        "!wget \"https://github.com/crwong/cs224u-project/blob/master/data/sentiment/training.1600000.processed.noemoticon.csv\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-08 12:31:59--  https://github.com/crwong/cs224u-project/blob/master/data/sentiment/training.1600000.processed.noemoticon.csv\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘training.1600000.processed.noemoticon.csv.1’\n",
            "\n",
            "training.1600000.pr     [ <=>                ] 102.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-03-08 12:31:59 (2.69 MB/s) - ‘training.1600000.processed.noemoticon.csv.1’ saved [104499]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRJlLlsF0bsC",
        "outputId": "a4387401-64eb-4eed-e5d8-a60531caae71"
      },
      "source": [
        "pip install keras==2.1.6"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.1.6 in /usr/local/lib/python3.7/dist-packages (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0r1W7kAxI1R"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Dropout\r\n",
        "from keras.layers.convolutional import Conv1D\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import spacy\r\n",
        "from pylab import *\r\n",
        "nlp=spacy.load(\"en\")\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMs73eUvxp7s",
        "outputId": "ab2ea30d-ad75-46b9-e6da-b810b03bf5b1"
      },
      "source": [
        "ls\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training.1600000.processed.noemoticon.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K30LKTz2xcyf",
        "outputId": "65eaf516-86fc-4eca-e19e-8395725fe0fe"
      },
      "source": [
        "#load the dataset\r\n",
        "train=pd.read_csv(\"training.1600000.processed.noemoticon.csv\" , encoding= \"latin-1\", error_bad_lines=False)\r\n",
        "Y_train = train[train.columns[0]]\r\n",
        "X_train = train[train.columns[0]]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 53: expected 1 fields, saw 2\\nSkipping line 58: expected 1 fields, saw 2\\nSkipping line 59: expected 1 fields, saw 2\\nSkipping line 73: expected 1 fields, saw 2\\nSkipping line 92: expected 1 fields, saw 193\\nSkipping line 93: expected 1 fields, saw 2\\nSkipping line 155: expected 1 fields, saw 3\\nSkipping line 167: expected 1 fields, saw 6\\nSkipping line 168: expected 1 fields, saw 7\\nSkipping line 193: expected 1 fields, saw 4\\nSkipping line 197: expected 1 fields, saw 2\\nSkipping line 210: expected 1 fields, saw 2\\nSkipping line 211: expected 1 fields, saw 2\\nSkipping line 217: expected 1 fields, saw 2\\nSkipping line 220: expected 1 fields, saw 2\\nSkipping line 228: expected 1 fields, saw 4\\nSkipping line 234: expected 1 fields, saw 2\\nSkipping line 239: expected 1 fields, saw 2\\nSkipping line 240: expected 1 fields, saw 2\\nSkipping line 241: expected 1 fields, saw 2\\nSkipping line 242: expected 1 fields, saw 2\\nSkipping line 243: expected 1 fields, saw 2\\nSkipping line 249: expected 1 fields, saw 2\\nSkipping line 250: expected 1 fields, saw 2\\nSkipping line 251: expected 1 fields, saw 2\\nSkipping line 252: expected 1 fields, saw 2\\nSkipping line 259: expected 1 fields, saw 2\\nSkipping line 267: expected 1 fields, saw 4\\nSkipping line 272: expected 1 fields, saw 2\\nSkipping line 275: expected 1 fields, saw 2\\nSkipping line 276: expected 1 fields, saw 2\\nSkipping line 280: expected 1 fields, saw 2\\nSkipping line 281: expected 1 fields, saw 2\\nSkipping line 303: expected 1 fields, saw 2\\nSkipping line 473: expected 1 fields, saw 6\\nSkipping line 474: expected 1 fields, saw 3\\nSkipping line 479: expected 1 fields, saw 6\\nSkipping line 480: expected 1 fields, saw 6\\nSkipping line 565: expected 1 fields, saw 6\\nSkipping line 572: expected 1 fields, saw 6\\nSkipping line 585: expected 1 fields, saw 6\\nSkipping line 601: expected 1 fields, saw 3\\nSkipping line 609: expected 1 fields, saw 3\\nSkipping line 617: expected 1 fields, saw 3\\nSkipping line 625: expected 1 fields, saw 3\\nSkipping line 633: expected 1 fields, saw 3\\nSkipping line 641: expected 1 fields, saw 3\\nSkipping line 649: expected 1 fields, saw 3\\nSkipping line 868: expected 1 fields, saw 7\\nSkipping line 924: expected 1 fields, saw 2\\nSkipping line 996: expected 1 fields, saw 2\\nSkipping line 999: expected 1 fields, saw 2\\nSkipping line 1017: expected 1 fields, saw 2\\nSkipping line 1052: expected 1 fields, saw 2\\nSkipping line 1053: expected 1 fields, saw 3\\nSkipping line 1054: expected 1 fields, saw 3\\nSkipping line 1055: expected 1 fields, saw 3\\nSkipping line 1056: expected 1 fields, saw 3\\nSkipping line 1057: expected 1 fields, saw 3\\nSkipping line 1064: expected 1 fields, saw 3\\nSkipping line 1065: expected 1 fields, saw 3\\nSkipping line 1066: expected 1 fields, saw 3\\nSkipping line 1067: expected 1 fields, saw 3\\nSkipping line 1068: expected 1 fields, saw 3\\nSkipping line 1069: expected 1 fields, saw 3\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY351hksxv-9"
      },
      "source": [
        "\r\n",
        "# split the data into test and train\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "trainset1x, trainset2x, trainset1y, trainset2y = train_test_split(X_train.values, Y_train.values, test_size=0.02,random_state=42 )\r\n",
        "trainset2y=pd.get_dummies(trainset2y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2odarHn0UxP"
      },
      "source": [
        "# function to remove stopwords\r\n",
        "def stopwords(sentence):\r\n",
        "   new=[]\r\n",
        "   sentence=nlp(sentence)\r\n",
        "   for w in sentence:\r\n",
        "      if (w.is_stop == False) & (w.pos_ !=\"PUNCT\"):\r\n",
        "        new.append(w.string.strip())\r\n",
        "        c=\" \".join(str(x) for x in new)\r\n",
        "      return c"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgrq2VyW1qoc"
      },
      "source": [
        "# function to lemmatize the tweets\r\n",
        "def lemmatize(sentence):\r\n",
        "    sentence=nlp(sentence)\r\n",
        "    str=\"\"\r\n",
        "    for w in sentence:\r\n",
        "        str+=\" \"+w.lemma_\r\n",
        "    return nlp(str)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb-NWCLI2aA4"
      },
      "source": [
        "#loading the glove model\r\n",
        "def loadGloveModel(gloveFile):\r\n",
        "    print(\"Loading Glove Model\")\r\n",
        "    f = open(gloveFile,'r')\r\n",
        "    model = {}\r\n",
        "    for line in f:\r\n",
        "        splitLine = line.split()\r\n",
        "        word = splitLine[0]\r\n",
        "        embedding = [float(val) for val in splitLine[1:]]\r\n",
        "        model[word] = embedding\r\n",
        "    print (\"Done.\"),len(model),(\" words loaded!\")\r\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkPqLpo632Kl",
        "outputId": "527bea82-13c7-401f-d122-f8aafbfee3c3"
      },
      "source": [
        "!wget \"https://www.kaggle.com/fullmetal26/glovetwitter27b100dtxt\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-08 12:46:09--  https://www.kaggle.com/fullmetal26/glovetwitter27b100dtxt\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘glovetwitter27b100dtxt’\n",
            "\n",
            "\rglovetwitter27b100d     [<=>                 ]       0  --.-KB/s               \rglovetwitter27b100d     [ <=>                ]  29.55K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-03-08 12:46:09 (11.3 MB/s) - ‘glovetwitter27b100dtxt’ saved [30261]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5QDrmT03ECU",
        "outputId": "74701d30-86d2-464a-c257-f0bd291c7087"
      },
      "source": [
        "ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glovetwitter27b100dtxt  training.1600000.processed.noemoticon.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "2DHjZv0Y2eYl",
        "outputId": "670292b9-d81e-4e8e-c8bb-1182363e3d4c"
      },
      "source": [
        "# save the glove model\r\n",
        "model=loadGloveModel(\"glove.twitter.27B.200d.txt\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-19587278be8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save the glove model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloadGloveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glove.twitter.27B.200d.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-ace69acd94a4>\u001b[0m in \u001b[0;36mloadGloveModel\u001b[0;34m(gloveFile)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadGloveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgloveFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Glove Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgloveFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.twitter.27B.200d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQDp4LFa2jhl"
      },
      "source": [
        "#vectorising the sentences\r\n",
        "def sent_vectorizer(sent, model):\r\n",
        "    sent_vec = np.zeros(200)\r\n",
        "    numw = 0\r\n",
        "    for w in sent.split():\r\n",
        "        try:\r\n",
        "            sent_vec = np.add(sent_vec, model[str(w)])\r\n",
        "            numw+=1\r\n",
        "        except:\r\n",
        "            pass\r\n",
        "    return sent_vec"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "89lwmgVL4G9l",
        "outputId": "4dc4b151-552a-496a-c8e9-089117ed0059"
      },
      "source": [
        "#obtain a clean vector\r\n",
        "cleanvector=[]\r\n",
        "for i in range(trainset2x.shape[0]):\r\n",
        "    document=trainset2x[i]\r\n",
        "    document=document.lower()\r\n",
        "    document=lemmatize(document)\r\n",
        "    document=str(document)\r\n",
        "    cleanvector.append(sent_vectorizer(document,model))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8d650c360d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdocument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcleanvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXh4iM8j4KvK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}